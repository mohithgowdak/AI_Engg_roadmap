{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Basics - Parsing LLM Outputs\n",
    "\n",
    "This module teaches you how to:\n",
    "1. Parse structured outputs from LLMs\n",
    "2. Use Pydantic models for validation\n",
    "3. Handle parsing errors\n",
    "4. Extract specific information from responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser, CommaSeparatedListOutputParser\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize local Ollama model\n",
    "llm = ChatOllama(\n",
    "    model=\"moondream:latest\",\n",
    "    temperature=0.7,\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "print(\"Setup complete! Using local Ollama model: moondream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pydantic Models\n",
    "\n",
    "Pydantic models define the structure of the output we expect from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic models for structured output\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person\"\"\"\n",
    "    name: str = Field(description=\"The person's full name\")\n",
    "    age: int = Field(description=\"The person's age\")\n",
    "    occupation: str = Field(description=\"The person's job or role\")\n",
    "    hobbies: List[str] = Field(description=\"List of hobbies\")\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    \"\"\"Recipe information\"\"\"\n",
    "    name: str = Field(description=\"Name of the recipe\")\n",
    "    ingredients: List[str] = Field(description=\"List of ingredients\")\n",
    "    steps: List[str] = Field(description=\"Cooking steps\")\n",
    "    prep_time: int = Field(description=\"Preparation time in minutes\")\n",
    "\n",
    "print(\"Pydantic models defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Pydantic Output Parser\n",
    "\n",
    "Use `PydanticOutputParser` to get structured, validated output from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parser for the Person model\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "# View the format instructions that will be sent to the LLM\n",
    "print(\"Format Instructions for LLM:\")\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt that includes format instructions\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. {format_instructions}\"),\n",
    "    (\"human\", \"Tell me about a fictional person named Alex who is a software engineer.\")\n",
    "])\n",
    "\n",
    "# Format the prompt with parser instructions\n",
    "formatted_prompt = prompt.format_messages(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(\"Raw Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the output\n",
    "try:\n",
    "    parsed_output = parser.parse(response.content)\n",
    "    \n",
    "    print(\"\\n‚úÖ Parsed Output:\")\n",
    "    print(f\"  Name: {parsed_output.name}\")\n",
    "    print(f\"  Age: {parsed_output.age}\")\n",
    "    print(f\"  Occupation: {parsed_output.occupation}\")\n",
    "    print(f\"  Hobbies: {', '.join(parsed_output.hobbies)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parsing error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: List Output Parser\n",
    "\n",
    "`CommaSeparatedListOutputParser` extracts comma-separated lists from LLM output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser for comma-separated lists\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. {format_instructions}\"),\n",
    "    (\"human\", \"List 5 programming languages.\")\n",
    "])\n",
    "\n",
    "formatted_prompt = prompt.format_messages(\n",
    "    format_instructions=list_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(f\"Raw Response: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the list\n",
    "try:\n",
    "    parsed_list = list_parser.parse(response.content)\n",
    "    \n",
    "    print(\"\\n‚úÖ Parsed List:\")\n",
    "    for i, item in enumerate(parsed_list, 1):\n",
    "        print(f\"  {i}. {item}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parsing error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Structured Output Parser\n",
    "\n",
    "Use `ResponseSchema` to define exactly what fields you want in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define response schemas\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"title\", description=\"Title of the book\"),\n",
    "    ResponseSchema(name=\"author\", description=\"Author of the book\"),\n",
    "    ResponseSchema(name=\"genre\", description=\"Genre of the book\"),\n",
    "    ResponseSchema(name=\"year\", description=\"Publication year\"),\n",
    "]\n",
    "\n",
    "structured_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "print(\"Format Instructions:\")\n",
    "print(structured_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a book expert. {format_instructions}\"),\n",
    "    (\"human\", \"Tell me about a famous science fiction book.\")\n",
    "])\n",
    "\n",
    "formatted_prompt = prompt.format_messages(\n",
    "    format_instructions=structured_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(f\"Raw Response:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the structured output\n",
    "try:\n",
    "    parsed_output = structured_parser.parse(response.content)\n",
    "    \n",
    "    print(\"\\n‚úÖ Parsed Output:\")\n",
    "    for key, value in parsed_output.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parsing error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Recipe Parser (Complex Pydantic Model)\n",
    "\n",
    "Parse more complex structured data like recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a chef. {format_instructions}\"),\n",
    "    (\"human\", \"Create a simple recipe for {dish}.\")\n",
    "])\n",
    "\n",
    "formatted_prompt = prompt.format_messages(\n",
    "    format_instructions=recipe_parser.get_format_instructions(),\n",
    "    dish=\"chocolate chip cookies\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(f\"Raw Response:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the recipe\n",
    "try:\n",
    "    recipe = recipe_parser.parse(response.content)\n",
    "    \n",
    "    print(f\"\\nüç™ Recipe: {recipe.name}\")\n",
    "    print(f\"\\n‚è±Ô∏è Prep Time: {recipe.prep_time} minutes\")\n",
    "    print(f\"\\nü•Ñ Ingredients:\")\n",
    "    for ingredient in recipe.ingredients:\n",
    "        print(f\"  - {ingredient}\")\n",
    "    print(f\"\\nüìù Steps:\")\n",
    "    for i, step in enumerate(recipe.steps, 1):\n",
    "        print(f\"  {i}. {step}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parsing error: {e}\")\n",
    "    print(\"The LLM output might not match the expected format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Error Handling in Parsing\n",
    "\n",
    "Always handle parsing errors gracefully since LLM outputs can be unpredictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse(parser, response_content, prompt=None):\n",
    "    \"\"\"Safely parse LLM output with error handling\"\"\"\n",
    "    try:\n",
    "        return parser.parse(response_content)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Primary parsing failed: {e}\")\n",
    "        \n",
    "        # Try recovery if prompt is provided\n",
    "        if prompt:\n",
    "            try:\n",
    "                return parser.parse_with_prompt(response_content, prompt)\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ö†Ô∏è Recovery also failed: {e2}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Test with a potentially problematic prompt\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. {format_instructions}\"),\n",
    "    (\"human\", \"Tell me about someone.\")\n",
    "])\n",
    "\n",
    "formatted_prompt = prompt.format_messages(\n",
    "    format_instructions=person_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(f\"Raw Response:\\n{response.content}\\n\")\n",
    "\n",
    "# Use safe parsing\n",
    "result = safe_parse(person_parser, response.content, formatted_prompt)\n",
    "\n",
    "if result:\n",
    "    print(f\"\\n‚úÖ Successfully parsed:\")\n",
    "    print(f\"  Name: {result.name}\")\n",
    "    print(f\"  Age: {result.age}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Could not parse the response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Using Parsers in Chains\n",
    "\n",
    "Integrate parsers directly into LCEL chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete chain with parsing\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. {format_instructions}\"),\n",
    "    (\"human\", \"List 5 {category}.\")\n",
    "])\n",
    "\n",
    "# Chain: prompt -> llm -> parser\n",
    "chain = prompt | llm | list_parser\n",
    "\n",
    "# Test with different categories\n",
    "categories = [\"fruits\", \"countries\", \"programming concepts\"]\n",
    "\n",
    "for category in categories:\n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"category\": category,\n",
    "            \"format_instructions\": list_parser.get_format_instructions()\n",
    "        })\n",
    "        print(f\"\\nüìå {category.upper()}:\")\n",
    "        for i, item in enumerate(result, 1):\n",
    "            print(f\"   {i}. {item}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Failed for {category}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **Output Parsers** structure LLM responses into usable data\n",
    "- **Pydantic models** provide type safety and validation\n",
    "- **CommaSeparatedListOutputParser** extracts lists\n",
    "- **StructuredOutputParser** handles custom schemas\n",
    "- **Always handle parsing errors** gracefully\n",
    "- Parsers can be integrated into **LCEL chains**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Create Your Own Parser\n",
    "\n",
    "Create a Pydantic model for a movie and parse movie information from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Create a Movie model and parser\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"Information about a movie\"\"\"\n",
    "    title: str = Field(description=\"Title of the movie\")\n",
    "    director: str = Field(description=\"Director's name\")\n",
    "    year: int = Field(description=\"Release year\")\n",
    "    genre: str = Field(description=\"Movie genre\")\n",
    "    rating: float = Field(description=\"Rating out of 10\")\n",
    "\n",
    "movie_parser = PydanticOutputParser(pydantic_object=Movie)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie expert. {format_instructions}\"),\n",
    "    (\"human\", \"Tell me about a classic sci-fi movie.\")\n",
    "])\n",
    "\n",
    "formatted_prompt = prompt.format_messages(\n",
    "    format_instructions=movie_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(f\"Raw Response:\\n{response.content}\\n\")\n",
    "\n",
    "try:\n",
    "    movie = movie_parser.parse(response.content)\n",
    "    print(f\"\\nüé¨ Movie: {movie.title}\")\n",
    "    print(f\"üé• Director: {movie.director}\")\n",
    "    print(f\"üìÖ Year: {movie.year}\")\n",
    "    print(f\"üé≠ Genre: {movie.genre}\")\n",
    "    print(f\"‚≠ê Rating: {movie.rating}/10\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parsing error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
